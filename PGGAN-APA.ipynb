{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCV_lcck7tAZ"
   },
   "outputs": [],
   "source": [
    "#from comet_ml import Experiment\n",
    "#experiment = Experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ccpy4OkFMEM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "from pickle import load, dump\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightScaledConv2d(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, kernel_size, stride=1, padding=0, spectral_norm=False):\n",
    "        super().__init__()\n",
    "        if spectral_norm:\n",
    "            self.conv = nn.utils.spectral_norm(nn.Conv2d(input_nc, output_nc, kernel_size, stride, padding))\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(input_nc, output_nc, kernel_size, stride, padding)\n",
    "        nn.init.kaiming_normal_(self.conv.weight)\n",
    "        #self.scale = torch.sqrt(2 / (kernel_size ** 2 * output_nc))\n",
    "        self.scale = nn.Parameter(torch.sqrt(torch.mean(self.conv.weight.data ** 2)))\n",
    "        self.conv.weight.data /= self.scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.scale\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3B8iWhv7tAg"
   },
   "outputs": [],
   "source": [
    "class PixelwiseNormalization(nn.Module):\n",
    "    def pixel_norm(self, x):\n",
    "        eps = 1e-8\n",
    "        return x * torch.rsqrt(torch.mean(x * x, 1, keepdim=True) + eps)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.pixel_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AMFgUr-7tAh"
   },
   "outputs": [],
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_channels, first=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if first:\n",
    "            self.model = nn.Sequential(\n",
    "                WeightScaledConv2d(input_nc, output_nc, kernel_size=4, stride=1, padding=3),\n",
    "                PixelwiseNormalization(),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                WeightScaledConv2d(output_nc, output_nc, kernel_size=3, stride=1, padding=1),\n",
    "                PixelwiseNormalization(),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                WeightScaledConv2d(input_nc, output_nc, kernel_size=3, stride=1, padding=1),\n",
    "                PixelwiseNormalization(),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                WeightScaledConv2d(output_nc, output_nc, kernel_size=3, stride=1, padding=1),\n",
    "                PixelwiseNormalization(),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "        \n",
    "        self.toRGB = WeightScaledConv2d(output_nc, num_channels, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def forward(self, image, last=False):\n",
    "        image = self.model(image)\n",
    "        if last:\n",
    "            image = self.toRGB(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F49S29BA7tAi"
   },
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_channels, last=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fromRGB = WeightScaledConv2d(num_channels, input_nc, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.last = last\n",
    "        if not last:\n",
    "            self.model = nn.Sequential(\n",
    "                WeightScaledConv2d(input_nc, output_nc, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                WeightScaledConv2d(output_nc, output_nc, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                WeightScaledConv2d(input_nc + 1, output_nc, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                WeightScaledConv2d(output_nc, output_nc, kernel_size=4, stride=1, padding=0),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "    \n",
    "    def minibatch_standard_deviation(self, x):\n",
    "        eps = 1e-8\n",
    "        return torch.cat([x, torch.sqrt(((x - x.mean())**2).mean() + eps).expand(x.shape[0], 1, *x.shape[2:])], dim=1)\n",
    "    \n",
    "    def forward(self, x, first=False):\n",
    "        if first:\n",
    "            x = self.fromRGB(x)\n",
    "        if self.last:\n",
    "            x = self.minibatch_standard_deviation(x)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d53nPWZFheB4"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_depth, num_channels, num_fmap):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks = nn.ModuleList(\n",
    "            [GeneratorBlock(num_fmap(0), num_fmap(1), num_channels, first=True)]\n",
    "            + [GeneratorBlock(num_fmap(i-1), num_fmap(i), num_channels) for i in range(2, num_depth + 1)]\n",
    "        )\n",
    "        \n",
    "        self.depth = 0\n",
    "        self.alpha = 1.0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2).unsqueeze(3)\n",
    "        rgb = x = self.blocks[0](x, self.depth == 0)\n",
    "        \n",
    "        if self.depth > 0:\n",
    "            for i in range(self.depth - 1):\n",
    "                x = F.interpolate(x, scale_factor=2) # upsample\n",
    "                x = self.blocks[i+1](x)\n",
    "            \n",
    "            x = F.interpolate(x, scale_factor=2) # upsample\n",
    "            rgb = self.blocks[self.depth](x, last=True)\n",
    "            \n",
    "            if self.alpha < 1.0:\n",
    "                prev_rgb = self.blocks[self.depth - 1].toRGB(x)\n",
    "                rgb = (1 - self.alpha) * prev_rgb + self.alpha * rgb\n",
    "        \n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0TccaIsSJxd"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_depth, num_channels, num_fmap):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks = nn.ModuleList(\n",
    "            [DiscriminatorBlock(num_fmap(i), num_fmap(i-1), num_channels) for i in range(num_depth, 1, -1)]\n",
    "            + [DiscriminatorBlock(num_fmap(1), num_fmap(0), num_channels, last=True)]\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(num_fmap(0), 1)\n",
    "        \n",
    "        self.depth = 0\n",
    "        self.alpha = 1.0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_high = x\n",
    "        \n",
    "        h = self.blocks[-(self.depth + 1)](x_high, first=True)\n",
    "        \n",
    "        if self.depth > 0:\n",
    "            h = F.avg_pool2d(h, 2) # downsample\n",
    "            \n",
    "            if self.alpha < 1.0:\n",
    "                x_low = F.avg_pool2d(x_high, 2) # downsample\n",
    "                prev = self.blocks[-self.depth].fromRGB(x_low)\n",
    "                h = self.alpha * h + (1 - self.alpha) * prev\n",
    "                \n",
    "        for i in range(self.depth, 0, -1):\n",
    "            h = self.blocks[-i](h)\n",
    "            if i > 1:\n",
    "                h = F.avg_pool2d(h, 2)  # downsample\n",
    "        \n",
    "        out = self.linear(h.squeeze(-1).squeeze(-1))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomErasing:\n",
    "    def __init__(self, p=0.5, erase_low=0.02, erase_high=0.33, aspect_rl=0.3, aspect_rh=3.3):\n",
    "        self.p = p\n",
    "        self.erase_low = erase_low\n",
    "        self.erase_high = erase_high\n",
    "        self.aspect_rl = aspect_rl\n",
    "        self.aspect_rh = aspect_rh\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if np.random.rand() <= self.p:\n",
    "            c, h, w = image.shape\n",
    "            \n",
    "            mask_area = np.random.uniform(self.erase_low, self.erase_high) * (h * w)\n",
    "            mask_aspect_ratio = np.random.uniform(self.aspect_rl, self.aspect_rh)\n",
    "            mask_w = int(np.sqrt(mask_area / mask_aspect_ratio))\n",
    "            mask_h = int(np.sqrt(mask_area * mask_aspect_ratio))\n",
    "            \n",
    "            mask = torch.Tensor(np.random.rand(c, mask_h, mask_w) * 255)\n",
    "            \n",
    "            left = np.random.randint(0, w)\n",
    "            top = np.random.randint(0, h)\n",
    "            right = left + mask_w\n",
    "            bottom = top + mask_h\n",
    "            \n",
    "            if right <= w and bottom <= h:\n",
    "                image[:, top:bottom, left:right] = mask\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meoyoQHI7tAm"
   },
   "outputs": [],
   "source": [
    "class Util:\n",
    "    @staticmethod\n",
    "    def loadImages(batch_size, folder_path, size):\n",
    "        imgs = ImageFolder(folder_path, transform=transforms.Compose([\n",
    "            transforms.Resize(int(size)),\n",
    "            transforms.RandomCrop(size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor()\n",
    "        ]))\n",
    "        return DataLoader(imgs, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def augment(images):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=0, contrast=0.5, saturation=0.5),\n",
    "            transforms.RandomRotation(degrees=30),\n",
    "            transforms.ToTensor(),\n",
    "            RandomErasing()\n",
    "        ])\n",
    "        device = images.device\n",
    "        return torch.cat([transform(img).unsqueeze(0) for img in images.cpu()], 0).to(device)\n",
    "    \n",
    "    @staticmethod\n",
    "    def showImages(dataloader):\n",
    "        %matplotlib inline\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        PIL = transforms.ToPILImage()\n",
    "        ToTensor = transforms.ToTensor()\n",
    "\n",
    "        for images in dataloader:\n",
    "            for image in images[0]:\n",
    "                img = PIL(image)\n",
    "                fig = plt.figure(dpi=200)\n",
    "                ax = fig.add_subplot(1, 1, 1) # (row, col, num)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(img)\n",
    "                #plt.gray()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHj4Xny37tAm"
   },
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, args):\n",
    "        use_cuda = torch.cuda.is_available() if not args.cpu else False\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(f'Use Device: {self.device}')\n",
    "        \n",
    "        def num_fmap(stage):\n",
    "            base_size = self.args.image_size\n",
    "            fmap_base = base_size * 4\n",
    "            fmap_max = base_size // 2\n",
    "            fmap_decay = 1.0\n",
    "            return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)\n",
    "        \n",
    "        self.args = args\n",
    "        self.num_channels = 3\n",
    "        self.feed_dim = num_fmap(0)\n",
    "        self.max_depth = int(np.log2(self.args.image_size)) - 1\n",
    "        self.depth = 0\n",
    "        \n",
    "        self.pseudo_aug = 0.0\n",
    "        self.epoch = 0\n",
    "        self.num_train = 0\n",
    "        \n",
    "        self.netG = Generator(self.max_depth, self.num_channels, num_fmap).to(self.device)\n",
    "        self.netD = Discriminator(self.max_depth, self.num_channels, num_fmap).to(self.device)\n",
    "        \n",
    "        self.optimizer_G = optim.Adam(self.netG.parameters(), lr=self.args.lr, betas=(0, 0.9))\n",
    "        self.optimizer_D = optim.Adam(self.netD.parameters(), lr=self.args.lr * self.args.mul_lr_dis, betas=(0, 0.9))\n",
    "        #self.scheduler_G = CosineAnnealingLR(self.optimizer_G, T_max=4, eta_min=self.args.lr/4)\n",
    "        #self.scheduler_D = CosineAnnealingLR(self.optimizer_D, T_max=4, eta_min=(self.args.lr * self.args.mul_lr_dis)/4)\n",
    "            \n",
    "    def load_dataset(self):\n",
    "        self.batch_size  = self.args.batch_size_base * (self.max_depth - self.depth)\n",
    "        image_size = self.args.image_size / 2 ** (self.max_depth - self.depth - 1)\n",
    "        self.dataloader = Util.loadImages(self.batch_size, self.args.image_dir, image_size)\n",
    "        self.max_iters = len(iter(self.dataloader))\n",
    "    \n",
    "    def save_state(self, epoch):\n",
    "        self.netG.cpu(), self.netD.cpu()\n",
    "        torch.save(self.netG.state_dict(), os.path.join(self.args.weight_dir, f'weight_G.{epoch}.pth'))\n",
    "        torch.save(self.netD.state_dict(), os.path.join(self.args.weight_dir, f'weight_D.{epoch}.pth'))\n",
    "        self.netG.to(self.device), self.netD.to(self.device)\n",
    "    \n",
    "    def load_state(self):\n",
    "        if (os.path.exists('weight_G.pth') and os.path.exists('weight_D.pth')):\n",
    "            self.netG.load_state_dict(torch.load('weight_G.pth', map_location=self.device))\n",
    "            self.netD.load_state_dict(torch.load('weight_D.pth', map_location=self.device))\n",
    "            self.state_loaded = True\n",
    "            print('Loaded network state.')\n",
    "    \n",
    "    def save_resume(self):\n",
    "        with open(os.path.join('.', f'resume.pkl'), 'wb') as f:\n",
    "            dump(self, f)\n",
    "    \n",
    "    def load_resume(self):\n",
    "        if os.path.exists('resume.pkl'):\n",
    "            with open(os.path.join('.', 'resume.pkl'), 'rb') as f:\n",
    "                print('Load resume.')\n",
    "                return load(f)\n",
    "        else:\n",
    "            return self\n",
    "    \n",
    "    def trainGAN(self, epoch, iters, max_iters, real_img, a=0, b=1, c=1):\n",
    "        ### Train with LSGAN.\n",
    "        ### for example, (a, b, c) = 0, 1, 1 or (a, b, c) = -1, 1, 0\n",
    "        \n",
    "        random_data = torch.randn(real_img.size(0), self.feed_dim).to(self.device)\n",
    "        \n",
    "        # ================================================================================ #\n",
    "        #                             Train the discriminator                              #\n",
    "        # ================================================================================ #\n",
    "        \n",
    "        # Compute loss with real images.\n",
    "        real_src_score = self.netD(real_img)\n",
    "        real_src_loss = torch.sum((real_src_score - b) ** 2)\n",
    "        \n",
    "        # Compute loss with fake images.\n",
    "        fake_img = self.netG(random_data)\n",
    "        fake_src_score = self.netD(fake_img)\n",
    "        \n",
    "        p = random.uniform(0, 1)\n",
    "        if 1 - self.pseudo_aug < p:\n",
    "            fake_src_loss = torch.sum((fake_src_score - b) ** 2) # Pseudo: fake is real.\n",
    "        else:\n",
    "            fake_src_loss = torch.sum((fake_src_score - a) ** 2)\n",
    "        \n",
    "        # Update Probability Augmentation.\n",
    "        lz = (torch.sign(torch.logit(real_src_score)).mean()\n",
    "              - torch.sign(torch.logit(fake_src_score)).mean()) / 2\n",
    "        if lz > self.args.aug_threshold:\n",
    "            self.pseudo_aug += self.args.aug_increment\n",
    "        else:\n",
    "            self.pseudo_aug -= self.args.aug_increment\n",
    "        self.pseudo_aug = min(1, max(0, self.pseudo_aug))\n",
    "        \n",
    "        # Backward and optimize.\n",
    "        d_loss = 0.5 * (real_src_loss + fake_src_loss) / self.batch_size\n",
    "        self.optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.optimizer_D.step()\n",
    "              \n",
    "        # Logging.\n",
    "        loss = {}\n",
    "        loss['D/loss'] = d_loss.item()\n",
    "        loss['Augment/prob'] = self.pseudo_aug\n",
    "        \n",
    "        # ================================================================================ #\n",
    "        #                               Train the generator                                #\n",
    "        # ================================================================================ #\n",
    "        # Compute loss with reconstruction loss\n",
    "        fake_img = self.netG(random_data)\n",
    "        fake_src_score = self.netD(fake_img)\n",
    "        fake_src_loss = torch.sum((fake_src_score - c) ** 2)\n",
    "        \n",
    "        # Backward and optimize.\n",
    "        g_loss = 0.5 * fake_src_loss / self.batch_size\n",
    "        self.optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        # Logging.\n",
    "        loss['G/loss'] = g_loss.item()\n",
    "        \n",
    "        # Save\n",
    "        if iters == max_iters:\n",
    "            self.save_state(epoch)\n",
    "            img_name = str(epoch) + '_' + str(iters) + '.png'\n",
    "            img_path = os.path.join(self.args.result_dir, img_name)\n",
    "            save_image(fake_img, img_path)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def train(self, resume=True):\n",
    "        hyper_params = {}\n",
    "        hyper_params['Image Dir'] = self.args.image_dir\n",
    "        hyper_params['Result Dir'] = self.args.result_dir\n",
    "        hyper_params['Weight Dir'] = self.args.weight_dir\n",
    "        hyper_params['Image Size'] = self.args.image_size\n",
    "        hyper_params['Learning Rate'] = self.args.lr\n",
    "        hyper_params[\"Mul Discriminator's LR\"] = self.args.mul_lr_dis\n",
    "        hyper_params['Batch Size Base'] = self.args.batch_size_base\n",
    "        hyper_params['Num Train Base'] = self.args.num_train_base\n",
    "        hyper_params['Probability Aug-Threshold'] = self.args.aug_threshold\n",
    "        hyper_params['Probability Aug-Increment'] = self.args.aug_increment\n",
    "        hyper_params['Max Depth'] = self.max_depth\n",
    "        hyper_params['Start Depth'] = self.depth + 1\n",
    "        \n",
    "        for key in hyper_params.keys():\n",
    "            print(f'{key}: {hyper_params[key]}')\n",
    "        #experiment.log_parameters(hyper_params)\n",
    "        \n",
    "        self.netG.train()\n",
    "        self.netD.train()\n",
    "        self.load_dataset()\n",
    "        \n",
    "        while True:\n",
    "            #max_train = self.num_train_base\n",
    "            max_train = int(self.args.num_train_base // np.log2(self.max_depth - self.depth + 1))\n",
    "            self.num_train += 1\n",
    "            self.epoch += 1\n",
    "            epoch_loss_G = 0.0\n",
    "            epoch_loss_D = 0.0\n",
    "            \n",
    "            for iters, (data, _) in enumerate(tqdm(self.dataloader)):\n",
    "                iters += 1\n",
    "                \n",
    "                alpha = self.num_train / max_train\n",
    "                alpha = min(1.0, alpha * 2)\n",
    "                self.netG.alpha = self.netD.alpha = alpha\n",
    "                \n",
    "                data = data.to(self.device)\n",
    "                \n",
    "                loss = self.trainGAN(self.epoch, iters, self.max_iters, data)\n",
    "                \n",
    "                epoch_loss_D += loss['D/loss']\n",
    "                epoch_loss_G += loss['G/loss']\n",
    "                #experiment.log_metrics(loss)\n",
    "            \n",
    "            epoch_loss = epoch_loss_G + epoch_loss_D\n",
    "            \n",
    "            print(f'Epoch[{self.epoch}] Depth[{self.depth+1}/{self.max_depth}]'\n",
    "                  + f' DepthTrain[{self.num_train}/{max_train}] BatchSize[{self.batch_size}]'\n",
    "                  #+ f' LR[G({self.scheduler_G.get_last_lr()[0]:.5f}) D({self.scheduler_D.get_last_lr()[0]:.5f})]'\n",
    "                  + f' Loss[G({epoch_loss_G}) + D({epoch_loss_D}) = {epoch_loss}]')\n",
    "                \n",
    "            #self.scheduler_G.step()\n",
    "            #self.scheduler_D.step()\n",
    "            \n",
    "            if self.num_train >= max_train:\n",
    "                if self.depth+1 < self.max_depth:\n",
    "                    self.depth += 1\n",
    "                    self.netG.depth = self.netD.depth = self.depth\n",
    "                    self.load_dataset()  # Change batch-size and image-size.\n",
    "                    self.num_train = 0\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            if not self.args.noresume:\n",
    "                self.save_resume()\n",
    "    \n",
    "    def generate(self, num=100):\n",
    "        self.netG.eval()\n",
    "        \n",
    "        for _ in range(num):\n",
    "            random_data = [torch.randn(1, self.netG.input_size).to(self.device)]\n",
    "            fake_img = self.netG(random_data)[0].cpu().data[0]\n",
    "            save_image(fake_img, os.path.join(self.args.result_dir, f'generated_{time.time()}.png'))\n",
    "            \n",
    "        print('New picture was generated.')\n",
    "    \n",
    "    def showImages(self):\n",
    "        depth = self.depth\n",
    "        self.depth = self.max_depth - 1\n",
    "        self.load_dataset()\n",
    "        Util.showImages(self.dataloader)\n",
    "        self.depth = depth\n",
    "        self.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC8jOA2N7tAp"
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    solver = Solver(args)\n",
    "    solver.load_state()\n",
    "    \n",
    "    if not args.noresume:\n",
    "        solver = solver.load_resume()\n",
    "    \n",
    "    if args.start_depth != 1:\n",
    "        solver.netG.depth = solver.netD.depth = solver.depth = args.start_depth - 1\n",
    "    \n",
    "    if args.generate > 0:\n",
    "        solver.generate(args.generate)\n",
    "        return\n",
    "    \n",
    "    #solver.showImages()\n",
    "    solver.train()\n",
    "    \n",
    "    #experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2njRAfXr7tAp"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--image_dir', type=str, default='')\n",
    "    parser.add_argument('--result_dir', type=str, default='results')\n",
    "    parser.add_argument('--weight_dir', type=str, default='weights')\n",
    "    parser.add_argument('--image_size', type=int, default=256)\n",
    "    parser.add_argument('--lr', type=float, default=0.0001)\n",
    "    parser.add_argument('--mul_lr_dis', type=float, default=4)\n",
    "    parser.add_argument('--batch_size_base', type=int, default=16)\n",
    "    parser.add_argument('--num_train_base', type=int, default=128)\n",
    "    parser.add_argument('--start_depth', type=int, default=1)\n",
    "    parser.add_argument('--aug_threshold', type=float, default=0.6)\n",
    "    parser.add_argument('--aug_increment', type=float, default=0.01)\n",
    "    parser.add_argument('--cpu', action='store_true')\n",
    "    parser.add_argument('--generate', type=int, default=0)\n",
    "    parser.add_argument('--noresume', action='store_true')\n",
    "    \n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    if not os.path.exists(args.result_dir):\n",
    "        os.mkdir(args.result_dir)\n",
    "    if not os.path.exists(args.weight_dir):\n",
    "        os.mkdir(args.weight_dir)\n",
    "    \n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StyleGAN1.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
